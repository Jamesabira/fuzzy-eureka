import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, Dropout
from tensorflow.keras.utils import to_categorical

# Load the database performance data and number of users
data = pd.read_csv('performance_data.csv')
num_users = data['num_users'].values

# Normalize the performance data
mean = np.mean(data['performance'].values)
stddev = np.std(data['performance'].values)
data['performance'] = (data['performance'] - mean) / stddev

# Label the data as normal or anomalous based on their deviation from the mean
data['label'] = np.where(data['performance'].abs() > 3 * stddev, 1, 0)

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(data[['num_users', 'performance']].values, data['label'].values, test_size=0.2)

# Reshape the data to be compatible with the CNN
X_train = X_train.reshape((-1, 1, 2))
X_test = X_test.reshape((-1, 1, 2))

# Convert the target labels to categorical format
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# Define the model architecture
model = Sequential()
model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(1, 2)))
model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))
model.add(MaxPooling1D(pool_size=2))
model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))
model.add(MaxPooling1D(pool_size=2))
model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))
model.add(GlobalMaxPooling1D())
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(2, activation='softmax'))

# Set the hyperparameters for the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
batch_size = 64
epochs = 50

# Train the model
history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))

# Evaluate the model on the test data
loss, accuracy = model.evaluate(X_test, y_test, batch_size=batch_size)
print('Test accuracy:', accuracy)

# Predict the labels for the test data
y_pred = model.predict(X_test)

# Count the number of users in the system
num_users_test = X_test[:,0,0]
num_users_test = num_users_test.astype(int)
num_users_count = np.unique(num_users_test, return_counts=True)

# Print the number of users and their counts in the test data
print('Number of users in the test data:', num_users_count[0])
print('Count of users in the test data:', num_users_count[1])
